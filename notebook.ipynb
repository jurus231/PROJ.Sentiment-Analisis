{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b256048",
   "metadata": {},
   "source": [
    "Step 1: Load Dataset\n",
    "\n",
    "Pada langkah pertama ini, kita akan mengimpor library pandas dan membaca dataset hasil scraping review dari Steam. Dataset ini berisi ulasan game yang nantinya akan kita olah lebih lanjut untuk analisis sentimen.\n",
    "\n",
    "Metode yang digunakan:\n",
    "\n",
    "    pd.read_csv() digunakan untuk membaca file .csv.\n",
    "\n",
    "    df.head() digunakan untuk menampilkan 5 baris pertama dari dataset agar kita bisa melihat struktur datanya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "438ea930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b97d1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enjoyable and calm game.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>very good game</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In it's current state, I wouldn't recommend th...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mantap\\r\\n</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bugged mess, worst than lol VALVe pls fix</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0                           Enjoyable and calm game.  positive\n",
       "1                                     very good game  positive\n",
       "2  In it's current state, I wouldn't recommend th...  positive\n",
       "3                                         mantap\\r\\n   neutral\n",
       "4          bugged mess, worst than lol VALVe pls fix  negative"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baca file hasil scraping\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/jurus231/PROJ.Sentiment-Analisis/refs/heads/main/steam_reviews_labeled.csv')\n",
    "\n",
    "# Tampilkan 5 data pertama\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b39adb8",
   "metadata": {},
   "source": [
    "Step 2: Preprocessing Teks\n",
    "\n",
    "Langkah ini bertujuan untuk membersihkan data teks agar siap diproses oleh model machine learning. Pembersihan ini dilakukan melalui beberapa tahapan penting:\n",
    "\n",
    "    Lowercase: Mengubah semua huruf menjadi huruf kecil agar konsisten.\n",
    "\n",
    "    Hapus URL: Menghapus tautan yang tidak relevan dengan analisis sentimen.\n",
    "\n",
    "    Hapus angka dan tanda baca: Untuk menyederhanakan teks.\n",
    "\n",
    "    Stopwords removal: Menghapus kata-kata umum seperti \"the\", \"and\", \"is\", dll., yang tidak memiliki makna penting dalam analisis sentimen.\n",
    "\n",
    "Setelah diproses, hasil teks bersih disimpan dalam kolom baru bernama clean_review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0978b10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\GEMINK1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enjoyable and calm game.</td>\n",
       "      <td>enjoyable calm game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>very good game</td>\n",
       "      <td>good game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In it's current state, I wouldn't recommend th...</td>\n",
       "      <td>current state wouldnt recommend game major cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mantap\\r\\n</td>\n",
       "      <td>mantap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bugged mess, worst than lol VALVe pls fix</td>\n",
       "      <td>bugged mess worst lol valve pls fix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0                           Enjoyable and calm game.   \n",
       "1                                     very good game   \n",
       "2  In it's current state, I wouldn't recommend th...   \n",
       "3                                         mantap\\r\\n   \n",
       "4          bugged mess, worst than lol VALVe pls fix   \n",
       "\n",
       "                                        clean_review  \n",
       "0                                enjoyable calm game  \n",
       "1                                          good game  \n",
       "2  current state wouldnt recommend game major cha...  \n",
       "3                                             mantap  \n",
       "4                bugged mess worst lol valve pls fix  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Jalankan ini sekali untuk download stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Definisikan stopwords bahasa Inggris\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Fungsi preprocessing\n",
    "def preprocess_text(text):\n",
    "    # 1. Ubah ke huruf kecil\n",
    "    text = text.lower()\n",
    "    # 2. Hapus URL\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # 3. Hapus angka dan tanda baca\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation + string.digits))\n",
    "    # 4. Tokenisasi dan hapus stopwords\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Terapkan preprocessing ke kolom 'review'\n",
    "df['clean_review'] = df['review'].astype(str).apply(preprocess_text)\n",
    "\n",
    "# Tampilkan hasil\n",
    "df[['review', 'clean_review']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c35fe1f",
   "metadata": {},
   "source": [
    "Step 3: Ekstraksi Fitur dan Pembagian Dataset\n",
    "\n",
    "Agar data teks bisa diproses oleh algoritma machine learning, kita perlu mengubahnya menjadi representasi numerik. Di langkah ini, kita menggunakan TF-IDF (Term Frequency-Inverse Document Frequency) untuk mengubah kata menjadi angka.\n",
    "\n",
    "    TfidfVectorizer(max_features=5000) menghasilkan representasi numerik berdasarkan kata-kata yang paling informatif di seluruh dataset.\n",
    "\n",
    "    Dataset kemudian dibagi menjadi training set dan testing set dengan rasio 80:20 menggunakan train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7b8b4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran data latih: 2993\n",
      "Ukuran data uji: 749\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ekstrak fitur dari kolom clean_review\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df['clean_review'])\n",
    "\n",
    "# Label target\n",
    "y = df['sentiment']\n",
    "\n",
    "# Split data: 80% train, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f'Ukuran data latih: {X_train.shape[0]}')\n",
    "print(f'Ukuran data uji: {X_test.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea5fd60",
   "metadata": {},
   "source": [
    "Step 4: Training dan Evaluasi Model\n",
    "\n",
    "Pada tahap ini, kita melatih model klasifikasi menggunakan Logistic Regression, salah satu algoritma yang sering digunakan untuk analisis sentimen.\n",
    "\n",
    "    model.fit() digunakan untuk melatih model pada data latih.\n",
    "\n",
    "    model.predict() digunakan untuk memprediksi sentimen dari data uji.\n",
    "\n",
    "    accuracy_score dan classification_report digunakan untuk mengevaluasi performa model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99779260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi: 95.33%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.84      0.98      0.91       175\n",
      "    positive       0.99      0.95      0.97       567\n",
      "\n",
      "    accuracy                           0.95       749\n",
      "   macro avg       0.95      0.74      0.78       749\n",
      "weighted avg       0.96      0.95      0.95       749\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Inisialisasi dan training model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediksi\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluasi\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Akurasi: {acc * 100:.2f}%\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e98c7ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dan vectorizer berhasil disimpan!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Simpan model\n",
    "joblib.dump(model, 'sentiment_logreg_model.pkl')\n",
    "\n",
    "# Simpan vectorizer\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
    "\n",
    "print(\"Model dan vectorizer berhasil disimpan!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
